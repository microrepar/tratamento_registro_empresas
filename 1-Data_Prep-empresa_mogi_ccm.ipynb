{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tratamento de Dados de Registro de Empresas\n",
    "\n",
    "Script para tratamento de dados e compactacao dos registros de empresas de Mogi das Cruzes por Período.\n",
    "\n",
    "This notebook contains basic statistical analysis and visualization of the data.\n",
    "\n",
    "### Data Sources\n",
    "- summary : Processed file from notebook 1-Data_Prep\n",
    "\n",
    "### Changes\n",
    "- 01-23-2024 : Started project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = datetime.today()\n",
    "\n",
    "startswith_file = 'LISTAGEM CADASTRO'\n",
    "\n",
    "in_dir_origem = Path.cwd() / \"data\" / \"raw\"\n",
    "in_dir_destino = Path.cwd() / \"data\" / \"processed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_files_origem = [f for f in in_dir_origem.glob('*.xlsx') \n",
    "                    if f.name.startswith(startswith_file)]\n",
    "\n",
    "in_files_destino = [f for f in in_dir_destino.glob('*.parquet') \n",
    "                    if f.name.startswith(startswith_file)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista somente os arquivos que não contém o seu respectivo .parquet na pasta processed\n",
    "file_name_destino = [f.name.split('.')[0] for f in in_files_destino]\n",
    "in_files = [f for f in in_files_origem if f.name.split('.')[0] not in file_name_destino]\n",
    "in_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes = {\n",
    "    'TELEFONE': str,\n",
    "    'CEP': str,\n",
    "    'RAMAL': str,\n",
    "    'CNPJ/CPF': str,\n",
    "    # 'FAX': 'string'\n",
    "}\n",
    "df_dict = {f.name.split('.')[0]: pd.read_excel(f, dtype=dtypes, sheet_name='FINAL') for f in in_files}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, dfi in df_dict.items():\n",
    "    print('>>>>>>>>>>', name)\n",
    "    print(dfi.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column Cleanup\n",
    "\n",
    "- Remove all leading and trailing spaces\n",
    "- Rename the columns for consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, dfi in df_dict.items():\n",
    "    # https://stackoverflow.com/questions/30763351/removing-space-in-dataframe-python\n",
    "    dfi.columns = [x.strip().lower() for x in dfi.columns]\n",
    "    print(dfi.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for name, dfi in df_dict.items():...    \n",
    "dfi = list(df_dict.values())[-1]\n",
    "{col: '' for i, col in enumerate(dfi.columns)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_rename = {\n",
    "    'cnpj/cpf': 'cnpj_cpf',\n",
    "    'rua': 'logradouro',\n",
    "    'complem': 'complemento',\n",
    "    'e-mail': 'email',\n",
    "    'quantidade de empregados': 'qtde_empregados',\n",
    "    'descrição do cnae': 'descricao_cnae'\n",
    "}\n",
    "\n",
    "for name, dfi in df_dict.items():\n",
    "    print('>>>>>>>>>>', name)\n",
    "    dfi.rename(columns=cols_to_rename, inplace=True)\n",
    "    print(dfi.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Up Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, dfi in df_dict.items():\n",
    "    dfi.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, dfi in df_dict.items():\n",
    "    dfi.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, dfi in df_dict.items():\n",
    "    print('>>>>>>>>>>', name)\n",
    "    print(dfi.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adiciona o ddd 11 para os números de telefones fixos e móveis válidos sem o ddd\n",
    "def adiciona_ddd(v):\n",
    "    if v is np.nan: return v\n",
    "    if len(v) == 10 and v.startswith('19') :\n",
    "        return f'{v:1>11}'\n",
    "    if len(v) == 9 and v.startswith('9'):\n",
    "        return f'{v:1>11}'\n",
    "    elif len(v) == 8 and v[0] not in ['9','1']:\n",
    "        return f'{v:1>10}'\n",
    "    return v\n",
    "\n",
    "for name, dfi in df_dict.items():\n",
    "    print('>>>>>>>>>>', name)\n",
    "    dfi['telefone'] = dfi['telefone'].apply(adiciona_ddd)\n",
    "    dfi['telefone'] = dfi['telefone'].replace({'0': np.nan},)\n",
    "    print(dfi['telefone'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, dfi in df_dict.items():\n",
    "    print('>>>>>>>>>>', name)\n",
    "    dfi['ramal'] = dfi['ramal'].replace({0: np.nan})\n",
    "    print(dfi[dfi['ramal'].notnull()  & (dfi['ramal'] != '0')]['ramal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, dfi in df_dict.items():\n",
    "    print('>>>>>>>>>>', name)\n",
    "    print(dfi[['cnae']].head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, dfi in df_dict.items():\n",
    "    print('>>>>>>>>>>', name)\n",
    "    dfi['cnpj_cpf'] = dfi['cnpj_cpf'].str.replace(r'[^0-9]', '', regex=True).str.rjust(14, '0')\n",
    "    print(dfi[dfi.duplicated(subset=['cnpj_cpf'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, dfi in df_dict.items():\n",
    "    print('>>>>>>>>>>', name)\n",
    "    print(dfi[dfi.duplicated(subset=['cnpj_cpf'])]['cnpj_cpf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_startswith_0(v):\n",
    "    if len(v) == 7:\n",
    "        return f'{v:0>8}'\n",
    "    return v\n",
    "\n",
    "for name, dfi in df_dict.items():\n",
    "    print('>>>>>>>>>>', name)\n",
    "    display(dfi[['cep']])\n",
    "    dfi['cep'] = dfi['cep'].str.replace(r'[^0-9]', '', regex=True)\n",
    "    dfi['cep'] = dfi['cep'].apply(set_startswith_0)\n",
    "    display(dfi[['cep']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, dfi in df_dict.items():\n",
    "    print('>>>>>>>>>>', name)\n",
    "    for col in dfi.columns:\n",
    "        if dfi[col].dtype == 'object':\n",
    "            dfi[col] = dfi[col].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, dfi in df_dict.items():\n",
    "    print('>>>>>>>>>>', name)\n",
    "    for col in dfi.columns:\n",
    "        print(f'{col:.<30}:', max([len(str(v)) for v in dfi[col]]))\n",
    "        print(f'{col:.<30}:', min([len(str(v)) for v in dfi[col]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, dfi in df_dict.items():\n",
    "    print('>>>>>>>>>>', name)\n",
    "\n",
    "    dfi['cnpj_cpf'] = dfi['cnpj_cpf'].str.rjust(14, '0')\n",
    "    display(dfi[dfi['cnpj_cpf'].isin(['00028500097841'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, dfi in df_dict.items():...    \n",
    "dfi.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfi.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "padrao_cnae = re.compile(r'^\\d{4}-\\d\\/\\d{2}$')\n",
    "\n",
    "cnae_dict = {}\n",
    "\n",
    "for name, dfi in df_dict.items():\n",
    "\n",
    "    tabela_cnae_empresas = {\n",
    "        'cnpj_cpf': [],\n",
    "        'cnae': [],\n",
    "    }\n",
    "\n",
    "    for _ , row in dfi.iterrows():\n",
    "        \n",
    "        cnpj_cpf = row['cnpj_cpf']\n",
    "        if cnpj_cpf == '191' and 'BANCO DO' not in row['nome']: continue\n",
    "\n",
    "        for i, cel in enumerate(row):\n",
    "            if i < 13 or not type(cel) == str: continue\n",
    "\n",
    "            if padrao_cnae.match(cel):\n",
    "                tabela_cnae_empresas['cnpj_cpf'].append(cnpj_cpf)\n",
    "                tabela_cnae_empresas['cnae'].append(cel)\n",
    "    \n",
    "    cnae_dict[name] = tabela_cnae_empresas\n",
    "\n",
    "cnae_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cnae_dict = {}\n",
    "for name, tabela in cnae_dict.items():\n",
    "    print('>>>>>>>>>>', name)\n",
    "    print(len(tabela['cnae']))\n",
    "    print(len(tabela['cnpj_cpf']))\n",
    "\n",
    "    df_cnae = pd.DataFrame(tabela)\n",
    "    df_cnae_dict[name] = df_cnae\n",
    "    print(df_cnae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save output file into processed directory\n",
    "\n",
    "Save a file in the processed directory that is cleaned properly. It will be read in and used later for further analysis.\n",
    "\n",
    "Other options besides pickle include:\n",
    "- feather\n",
    "- msgpack\n",
    "- parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, dfi in df_cnae_dict.items():\n",
    "    novo_nome = f'{name} - outros cnae.parquet'\n",
    "    summary_file_cnae = in_dir_destino / novo_nome\n",
    "    dfi.to_parquet(summary_file_cnae)\n",
    "\n",
    "for name, dfi in df_dict.items():\n",
    "    print('>>>>>>>>>>', name)\n",
    "    summary_file = in_dir_destino / f'{name}.parquet'\n",
    "    dfi.to_parquet(summary_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "3c06e3e46abf38078fe4dac36a0085ec2b134ebbd73dd076183d243eeca6918f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
