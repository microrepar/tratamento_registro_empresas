{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tratamento de Dados de Registro de Empresas\n",
    "\n",
    "Script para tratamento de dados e compactacao dos registros de empresas de Mogi das Cruzes por Período.\n",
    "\n",
    "This notebook contains basic statistical analysis and visualization of the data.\n",
    "\n",
    "### Data Sources\n",
    "- summary : Processed file from notebook 1-Data_Prep\n",
    "\n",
    "### Changes\n",
    "- 01-23-2024 : Started project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = datetime.today()\n",
    "\n",
    "startswith_file = 'CNPJ DE MOGI'\n",
    "\n",
    "in_dir_origem = Path.cwd() / \"data\" / \"raw\"\n",
    "in_dir_destino = Path.cwd() / \"data\" / \"processed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_files_origem = [f for f in in_dir_origem.glob('*.xlsx') \n",
    "                    if f.name.startswith(startswith_file)]\n",
    "\n",
    "in_files_destino = [f for f in in_dir_destino.glob('*.parquet') \n",
    "                    if f.name.startswith(startswith_file)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista somente os arquivos que não contém o seu respectivo .parquet na pasta processed\n",
    "file_name_destino = [f.name.split('.')[0] for f in in_files_destino]\n",
    "in_files = [f for f in in_files_origem if f.name.split('.')[0] not in file_name_destino]\n",
    "in_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes = {\n",
    "    'FAX': str,\n",
    "    'DDD FAX': str,\n",
    "    'DDD 1': str,\n",
    "    'TELEFONE 1': str,\n",
    "    'DDD 2': str,\n",
    "    'TELEFONE 2': str,\n",
    "    'DATA SITUAÇÃO': str,\n",
    "    'INICIO ATIV': str,\n",
    "    'CEP': str,\n",
    "    'CNPJ': str,\n",
    "    'CNAE PRINCIPAL': str,\n",
    "    'CNAE SECUNDARIA': str,\n",
    "}\n",
    "\n",
    "df_dict = {f.name.split('.')[0]: pd.read_excel(f, dtype=dtypes) for f in in_files}\n",
    "for name, dfi in df_dict.items():...\n",
    "dfi.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column Cleanup\n",
    "\n",
    "- Remove all leading and trailing spaces\n",
    "- Rename the columns for consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, dfi in df_dict.items():\n",
    "    # https://stackoverflow.com/questions/30763351/removing-space-in-dataframe-python\n",
    "    dfi.columns = [x.strip().lower() for x in dfi.columns]\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, dfi in df_dict.items():...\n",
    "{col: '' for col in dfi.columns}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_rename = {\n",
    "    'identif m/f': 'id_matriz_filial',\n",
    "    'nome empresarial': 'nome_empresarial',\n",
    "    'nome fantasia': 'nome_fantasia',\n",
    "    'natureza juridica': 'natureza_juridica',\n",
    "    'capital social': 'capital_social',\n",
    "    'situação cadastral': 'situcacao_cadastral',\n",
    "    'data situação': 'data_situacao',\n",
    "    'motivo da situação': 'motivo_situacao',\n",
    "    'inicio ativ': 'inicio_atividade',\n",
    "    'cnae principal': 'cnae',\n",
    "    'cnae secundaria': 'cnae_secundaria',\n",
    "    'tp lograd': 'tp_logradouro',\n",
    "    'compl': 'complemento',\n",
    "    'ddd 1': 'ddd1',\n",
    "    'telefone 1': 'telefone1',\n",
    "    'ddd 2': 'ddd2',\n",
    "    'telefone 2': 'telefone2',\n",
    "    'ddd fax': 'ddd_fax',\n",
    "}\n",
    "for name, dfi in df_dict.items():\n",
    "    dfi.rename(columns=cols_to_rename, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, dfi in df_dict.items():...\n",
    "dfi.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Up Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, dfi in df_dict.items():...\n",
    "dfi.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, dfi in df_dict.items():\n",
    "    dfi.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retira espaços em branco nas estremidades dos nomes das colunas\n",
    "for name, dfi in df_dict.items():\n",
    "    for col in dfi.columns:\n",
    "        if dfi[col].dtype == 'object':\n",
    "            dfi[col] = dfi[col].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, dfi in df_dict.items():...\n",
    "print('>>>>>>>>>>', name)\n",
    "print(dfi.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, dfi in df_dict.items():\n",
    "    print('>>>>>>>>>>', name)\n",
    "    print(dfi[['cnpj']].head())\n",
    "    dfi['cnpj'] = dfi['cnpj'].str.replace(r'[^0-9]', '', regex=True).str.rjust(14, '0')\n",
    "    print(dfi[['cnpj']].head())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, dfi in df_dict.items():\n",
    "    print('>>>>>>>>>>', name)\n",
    "    print(dfi[['capital_social']].head())\n",
    "    dfi['capital_social'] = (dfi['capital_social'].str.replace('.', '', regex=False)\n",
    "                                                .str.replace(',', '.', regex=False))\n",
    "    print(dfi[['capital_social']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, dfi in df_dict.items():\n",
    "    print('>>>>>>>>>>', name)\n",
    "    print(dfi['inicio_atividade'])\n",
    "    print(dfi['data_situacao'])\n",
    "    dfi['inicio_atividade'] = dfi['inicio_atividade'].str[:4]  +'-'+ dfi['inicio_atividade'].str[4:6] +'-'+dfi['inicio_atividade'].str[6:] \n",
    "    dfi['data_situacao'] = dfi['data_situacao'].str[:4]  +'-'+ dfi['data_situacao'].str[4:6] +'-'+dfi['data_situacao'].str[6:] \n",
    "    print(dfi['inicio_atividade'])\n",
    "    print(dfi['data_situacao'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "\n",
    "def parse_date(date_string):\n",
    "    if date_string is np.nan: return np.nan\n",
    "    # Check for the presence of a 4-digit year\n",
    "    four_digit_year_pattern = r'^\\d{2}-\\d{2}-\\d{4}$'\n",
    "    # Check for the presence of a 2-digit year\n",
    "    two_digit_year_pattern = r'^\\d{2}-\\d{2}-\\d{2}$'\n",
    "    \n",
    "    four_digit_year_pattern2 = r'^\\d{4}-\\d{2}-\\d{2}$'\n",
    "\n",
    "    # Check for the presence of a 4-digit year br\n",
    "    br_four_digit_year_pattern = r'^\\d{2}/\\d{2}/\\d{4}$'\n",
    "    # Check for the presence of a 2-digit year br\n",
    "    br_two_digit_year_pattern = r'^\\d{2}/\\d{2}/\\d{2}$'\n",
    "\n",
    "    if re.match(four_digit_year_pattern2, date_string):\n",
    "        return datetime.strptime(date_string, '%Y-%m-%d')\n",
    "    if re.match(four_digit_year_pattern, date_string):\n",
    "        return datetime.strptime(date_string, \"%d-%m-%Y\")\n",
    "    elif re.match(two_digit_year_pattern, date_string):\n",
    "        return datetime.strptime(date_string, \"%d-%m-%y\")\n",
    "    elif re.match(br_four_digit_year_pattern, date_string):\n",
    "        try:\n",
    "            data = datetime.strptime(date_string, \"%d/%m/%Y\")\n",
    "            return data \n",
    "        except:\n",
    "            print('>>>>>>>>>>>>', date_string)\n",
    "            mes, dia, ano = date_string.split('/')\n",
    "            return datetime.strptime(f'{dia}/{mes}/{ano[-2:]}', \"%d/%m/%y\")\n",
    "\n",
    "    elif re.match(br_two_digit_year_pattern, date_string):\n",
    "        return datetime.strptime(date_string, \"%d/%m/%y\")\n",
    "    return None\n",
    "\n",
    "\n",
    "for name, dfi in df_dict.items():\n",
    "    print('>>>>>>>>>>', name)\n",
    "    dfi['data_situacao'] = dfi['data_situacao'].apply(parse_date)\n",
    "    print(dfi[['data_situacao']].head(5))\n",
    "\n",
    "\n",
    "    dfi['inicio_atividade'] = pd.to_datetime(dfi['inicio_atividade'])\n",
    "    print(dfi[['inicio_atividade']].head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, dfi in df_dict.items():\n",
    "    print('>>>>>>>>>>', name)\n",
    "    print(dfi['numero'].astype(str).str.replace(r'[0-9]', '', regex=True).unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, dfi in df_dict.items():\n",
    "    print('>>>>>>>>>>', name)\n",
    "    for col in dfi.columns:\n",
    "        print(f'{col:.<30}:', max([len(str(v)) for v in dfi[col]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, dfi in df_dict.items():\n",
    "    print('>>>>>>>>>>', name)\n",
    "    display(dfi[dfi['nome_empresarial'].str.contains('BANCO DO BRASIL')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, dfi in df_dict.items():\n",
    "    print('>>>>>>>>>>', name)\n",
    "    display(dfi[['inicio_atividade', 'cnae', 'cnae_secundaria', 'tp_logradouro', 'logradouro', 'numero', 'complemento', 'bairro', 'cep', 'uf', 'ddd1', 'telefone1', 'ddd2', 'telefone2', 'ddd_fax', 'fax', ]].head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, dfi in df_dict.items():\n",
    "    print('>>>>>>>>>>', name)\n",
    "    dfi['cep'] = dfi['cep'].str.rjust(8, '0')\n",
    "    display(dfi[['cep']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, dfi in df_dict.items():\n",
    "    print('>>>>>>>>>>', name)\n",
    "    print(dfi[['cnae']])\n",
    "    dfi['cnae'] = dfi['cnae'].str.replace(r'[^0-9]', '', regex=True)    #.str.rjust(7, '0')\n",
    "    dfi['cnae'] = dfi['cnae'].str[:-3] +'-'+ dfi['cnae'].str[-3:-2] +'/'+ dfi['cnae'].str[-2:]\n",
    "    print(dfi[['cnae']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnae = '6920601'\n",
    "# cnae[:-3] +'-'+ cnae[-3:-2] +'/'+ cnae[-2:]\n",
    "f'{cnae[:-3]}-{cnae[-3:-2]}/{cnae[-2:]}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save output file into processed directory\n",
    "\n",
    "Save a file in the processed directory that is cleaned properly. It will be read in and used later for further analysis.\n",
    "\n",
    "Other options besides pickle include:\n",
    "- feather\n",
    "- msgpack\n",
    "- parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, dfi in df_dict.items():\n",
    "    print('>>>>>>>>>>', name)\n",
    "    summary_file = in_dir_destino / f'{name}.parquet'\n",
    "    dfi.to_parquet(summary_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "3c06e3e46abf38078fe4dac36a0085ec2b134ebbd73dd076183d243eeca6918f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
